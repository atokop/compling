Roger Pielke Jr.'s Blog






skip to main  |
      skip to sidebar



















04 September 2011





Faith-Based Education and a Return to Shop Class



Today's NYT has a lengthy front page article that wonders why investments in classroom technology do not lead to better educational outcomes among students:
To be sure, test scores can go up or down for many reasons. But to many  education experts, something is not adding up — here and across the  country. In a nutshell: schools are spending billions on technology,  even as they cut budgets and lay off teachers, with little proof that  this approach is improving basic learning.        In 2008 Dick Nelson and Dan Sarewitz had a commentary in Nature (here in PDF) that eloquently summarized why it is that we should not expect technology in the classroom to reault in better educational outcomes as they suggest we should in the case of a tehcnology like vaccines.

They introduce three rules for technological fixes as follows:
For some social problems, scientific research and technological innovation deliver significant progress, while for others, such activities lead to little if any improvement. Remarkable advances have been made in disease reduction through vaccination efforts, for example. But the story for literacy is different. In the United States, nearly a half century of research, application of new technologies and development of new methods and policies has failed to translate into improved reading abilities for the nation’s children1.

Although vaccinating children and teaching them to read may seem so different as\ to make them incommensurable, they are similar in several important respects. Both are carried out by trained professionals in a\ controlled environment using the standard tools of their respective trades. Notably, each has been, and continues to be, the subject of considerable research. But the reasons why progress has been so uneven point to three simple rules for anticipating when more research and development (R&D) could help to yield rapid social progress. In a world of limited resources, the trick is distinguishing problems amenable to technological fixes from those that are not. Our rules provide guidance\ in making this distinction . . .

Both vaccinating and teaching involve skilfully produced artefacts. But unlike vaccines, the textbooks and software used in education do not embody the essence of what needs to be done. That is, they don’t provide the basic ‘go’ of teaching and learning. That depends on the skills of teachers and on the attributes of classrooms and students. Most importantly, the effectiveness of a vaccine is largely independent of who gives or receives it, and of the setting in which it is given. A health-care practitioner (unlike a teacher) doesn’t usually have to figure out what will work on a case-by- case basis — no matter if the child is rich or poor, if he or she speaks English or Mandarin. The vaccine captures the basic go in a technological artefact, distinguishing it from the teaching of reading.The three rules for a technological fix proposed by Sarewitz and Nelson are:
I. The technology must largely embody the cause–effect relationship connecting problem to solution.
II. The effects of the technological fix must be assessable using relatively unambiguous or uncontroversial criteria.
III. Research and development is most likely to contribute decisively  to solving a social problem when it focuses on improving a standardized  technical core that already exists.Obviously technology in the classroom fails with respect to each of the three criteria: (a) technology is not a causal factor in learning in the sense that more technology means more learning, (b) assessment of educational outcome sis itself difficult and contested, much less disentangling various causal factors, and (c) the lack of evidence that technology leads to improved educational outcomes means that there is no such standardized technological core.

The NY Times reports:
This conundrum calls into question one of the most significant  contemporary educational movements. Advocates for giving schools a major  technological upgrade — which include powerful educators, Silicon  Valley titans and White House appointees — say digital devices let  students learn at their own pace, teach skills needed in a modern  economy and hold the attention of a generation weaned on gadgets.         

Some backers of this idea say standardized tests, the most widely used  measure of student performance, don’t capture the breadth of skills that  computers can help develop. But they also concede that for now there is  no better way to gauge the educational value of expensive technology  investments.        

“The data is pretty weak. It’s very difficult when we’re pressed to come  up with convincing data,” said Tom Vander Ark, the former executive  director for education at the Bill and Melinda Gates Foundation and an  investor in educational technology companies. When it comes to showing  results, he said, “We better put up or shut up.”        

And yet, in virtually the same breath, he said change of a historic  magnitude is inevitably coming to classrooms this decade: “It’s one of  the three or four biggest things happening in the world today.”        

Critics counter that, absent clear proof, schools are being motivated by  a blind faith in technology and an overemphasis on digital skills —  like using PowerPoint and multimedia tools — at the expense of math,  reading and writing fundamentals. They say the technology advocates have  it backward when they press to upgrade first and ask questions later.         In this case, the evidence would seem to show fairly conclusively that the critics are right. Yet, despite the lack of evidence for the efficacy of technology in the classroom, the lack of data has not been an obstacle to developing a long-term love affair with the promise of technology.
In 1997, a science and technology committee assembled by President  Clinton issued an urgent call about the need to equip schools with  technology.

If such spending was not increased by billions of dollars, American  competitiveness could suffer, according to the committee, whose members  included educators like Charles M. Vest, then president of the  Massachusetts Institute of Technology, and business executives like John  A. Young, the former chief executive of Hewlett-Packard.        

To support its conclusion, the committee’s report cited the successes of  individual schools that embraced computers and saw test scores rise or  dropout rates fall. But while acknowledging that the research on  technology’s impact was inadequate, the committee urged schools to adopt  it anyhow.

The report’s  final sentence read: “The panel does not, however, recommend that the  deployment of technology within America’s schools be deferred pending  the completion of such research.”        A 2010 review by the US Department of Education (here in PDF) found very few systematic studies of the role of technology in K-12 education.  WHat this means is that the advocates of technology in the classroom as a means of improving educational outcomes are basing their advocacy on little more than faith -- faith that technology will make outcomes better, despite a lack of evidence to support that faith.

This sort of faith-based education will have consequences, consider this vignette from the Arizona school at the center of the NYT story:
“We have Smart Boards in every classroom but not enough money to buy  copy paper, pencils and hand sanitizer,” said Nicole Cates, a  co-president of the Parent Teacher Organization at Kyrene de la Colina,  an elementary school . . .

But she loves the fact that her two children, a fourth-grader and  first-grader, are learning technology, including PowerPoint and  educational games.The love affair with technology reflects a deeper problem in education, hinted at in this week's Economist:
[D]emand for educated labour is being reconfigured by technology, in  much the same way that the demand for agricultural labour was  reconfigured in the 19th century and that for factory labour in the  20th. Computers can not only perform repetitive mental tasks much faster  than human beings. They can also empower amateurs to do what  professionals once did: why hire a flesh-and-blood accountant to  complete your tax return when Turbotax (a software package) will do the  job at a fraction of the cost? And the variety of jobs that computers  can do is multiplying as programmers teach them to deal with tone and  linguistic ambiguity.

Several economists, including Paul Krugman, have begun to argue that  post-industrial societies will be characterised not by a relentless rise  in demand for the educated but by a great “hollowing out”, as mid-level  jobs are destroyed by smart machines and high-level job growth slows.  David Autor, of the Massachusetts Institute of Technology (MIT), points  out that the main effect of automation in the computer era is not that  it destroys blue-collar jobs but that it destroys any job that can be  reduced to a routine. Alan Blinder, of Princeton University, argues that  the jobs graduates have traditionally performed are if anything more  “offshorable” than low-wage ones. A plumber or lorry-driver’s job cannot  be outsourced to India.So by all means lets have more technology in our education system -- such as technologies of operating machine tools, agricultural equipment, power systems and even food old-fashioned shop class.





Posted by
Roger Pielke, Jr.


at
9/04/2011 09:21:00 AM



12
comments


Links to this post























02 September 2011





Energy Efficiency and Carbon Emissions: Class Assignment



Here is the assignment I gave my students in my graduate seminar on energy efficiency, motivated by this well done article:
Here is an optional exercise for you to contemplate over the holiday weekend.  (It might make for a good final exam question, hint, hint).

1. The world consumes about 500 quads of energy today
2. Projections are that the world will consume 700 quads by 2030
3. Energy efficiency (EE) can be thought of as the inverse of energy intensity (EI) -- that is GDP/TE rather than TE/GDP -- so an increase in energy efficiency is equivalent to a decrease in energy intensity.
4. In the Kaya Identity CO2/GDP equals the product of energy intensity and carbon intensity -- CO2/GDP = TE/GDP * CO2/TE
5. Using your new-found appreciation of Excel and exponential growth equations, please calculate the rate of efficiency gains necessary to offset the projected increase in energy consumption by 2030 (#2 above)
6. Do the same thing for a 30% reduction in energy consumption from 2011
7. If the world consumed 355 quads in 1990, how do your projected rates of efficiency gain compare with reductions in EI from 1990-2011?
8. Convert your numbers in #5 and #6 into (a) carbon dioxide emissions and (b) nuclear power plants equivalent
9. What does this math say about the potential for efficiency to contribute to emissions reduction goals? If not efficiency, then what? (Hint look at the Kaya Identity)
10. BTW, the numbers in #1 and #2 leave 1.5 billion people in the dark with no energy access.  So redo the exercise assuming (a) these people gain energy access at 20% of today's per capita US level (i.e., add 100 quads to #2), (b) these people gain energy access at 50% of the 2011 US level (i.e., add 250 quads to #2).

Understanding these numbers is, I think, a prerequisite to having a complete understanding of the role of efficiency gains in the debate over emissions.

To be clear on my views -- from TCF and the magazine article that I shared with you will know that I think that (a) energy efficiency is a very good thing and should be pursued, and (b) it is very limited in its potential to contribute to goals for emissions reductions.  The math exercise above will help you to understand why I have come to this conclusion.




Posted by
Roger Pielke, Jr.


at
9/02/2011 02:53:00 PM



3
comments


Links to this post

























Retraction, Remote Sensing and Due Process



[UPDATE 9/4: A reader writes in to remind me of my own related posts here and here and here.] 

[UPDATE 9/4: Pielke Sr. has some thoughtful comments here.] 

[UPDATE 9/3: The circus continues:
Kevin Trenberth received a personal note of apology from both the editor-in-chief and the publisher of Remote Sensing.Why in the world would Trenberth need to be apologized to? Simply bizarre.]

The blogosphere is all atwitter over the news that the editor of the journal Remote Sensing has resigned to atone for what he believes to be a failure of his oversight of the journal by allowing what he asserts is a fatally flawed paper by climate skeptics to pass peer review and to be published.

The editor explains in an editorial published today that the paper in question "is most likely problematic" with respect to "fundamental methodological errors" and "false claims" and consequently "should therefore not have been published."

I am in no position to evaluate the substantive claims of errors and false claims in the paper, but I do agree with the folks over at RetractionWatch who call the resignation "curious" and ask if the editor feels as he does, "why not simply retract it?" In fact, if a paper has "errors" and "false claims" then a journal editor has an obligation to retract a paper (while of course giving the authors proper due process). In this case, the fact that the editor is unwilling or unable to retract the paper suggests that his resignation is probably the best course of action.

It is important for the new editor and editorial board of remote sensing to initiate retraction proceedings for the paper in question -- in other words the charges levied by the resigning editor need to be properly adjudicated. This is both in fairness to the authors (and the rest of us observers) but also good for science.

If the charges of "error" and "false claims" are upheld the paper should certainly be retracted.  If the charges are not upheld then the authors have every right to have such a judgment announced publicly.

Absent such an adjudication we are left with climate science played out as political theater in the media and on blogs -- with each side claiming the righteousness of their views, while everyone else just sees the peer review process in climate science getting another black eye.




Posted by
Roger Pielke, Jr.


at
9/02/2011 02:42:00 PM



23
comments


Links to this post























31 August 2011





Oil Shocks and Good Times for the Global Economy



This post revisits the topic of oil prices and economic growth which was explored here earlier this year.  A new paper by Tobias Rasmussen and Agustin Roitmanfrom the IMF (here in PDF) titled "Oil Shocks in a Global Perspective: Are they Really that Bad?" which explores the largely uncharted territory of the effects of oil price increases on economic growth at the global level.  The figuer at the top shows the countries with GDPs that increase following and oil shock (those bars above the horizontal axis) and those the see a decrease (those at the left side, the US and Japan are highlighted in yellow).

Here are the paper's conclusions:
Conventional wisdom has it that oil shocks are bad for oil-importing countries. This is grounded in the experience of slumps in many advanced economies during the 1970s. It is also consistent with the large body of research on the impact of higher oil prices on the U.S. economy, although the magnitude and channels of the effect are still being debated. In this paper, we offer a global perspective on the macroeconomic impact of oil prices. In doing so, we are filling a void of research on the effects of oil prices on developing economies.

Our findings indicate that oil prices tend to be surprisingly closely associated with good times for the global economy. Indeed, we find that the United States has been somewhat of an outlier in the way that it has been negatively affected by oil price increases. Across the world, oil price shock episodes have generally not been associated with a contemporaneous decline in output but, rather, with increases in both imports and exports. There is evidence of lagged negative effects on output, particularly for OECD economies, but the magnitude has typically been small.

Controlling for global economic conditions, and thus abstracting from our finding that oil price
increases generally appear to be demand-driven, makes the impact of higher oil prices stand out more clearly. For a given level of world GDP, we do find that oil prices have a negative effect on oil-importing countries and also that cross-country differences in the magnitude of the impact depend to a large extent on the relative magnitude of oil imports. The effect is still not particularly large, however, with our estimates suggesting that a 25 percent increase in oil prices will cause a loss of real GDP in oil-importing countries of less than half of one percent, spread over 2–3 years. One likely explanation for this relatively modest impact is that part of the greater revenue accruing to oil exporters will be recycled in the form of imports or other international flows, thus contributing to keep up demand in oil-importing economies. We provide a model illustrating this effect and find supporting empirical evidence.

The finding that the negative impact of higher oil prices has generally been quite small does not mean that the effect can be ignored. Some countries have clearly been negatively affected by high oil prices. Moreover, our results do not rule out more adverse effects from a future shock that is driven largely by lower oil supply than the more demand-driven increases in oil prices that have been the norm in the last two decades. In terms of policy lessons, our findings suggest that efforts to reduce dependence on oil could help reduce the exposure to oil price shocks and hence costs associated with macroeconomic volatility.13 At the same time, given a certain level of oil imports, developing economic linkages to oil exporters could also work as a natural shock absorber.If oil shocks are not so bad in aggregate, and associated with "good times for the global economy" then maybe the price of oil should be higher? 

H/T VoxEu




Posted by
Roger Pielke, Jr.


at
8/31/2011 11:08:00 AM



11
comments


Links to this post

























Comment of the Day: The Wrong Side of History, Science and Policy



This delightful and revealing comment, apparently offered as a defense of Governor Pete Shumlin's remarks that I discussed yesterday, provides a nice capsule summary of my experiences in the climate debate. 
Verbose and prolific (and cleverly snarky), most of the views expressed  by this blog author are on the wrong side of history, climate science,  and climate policy.  I understood from multiple posts not so long ago  that Dr. Pielke was going to transition to discourse on the subject of  technology policy on this blog rather than climate policy.  Like a moth  to a flame, the content authored here remains mostly climate-based, a  testament to the seduction of the defense of past positions.  While the  influence of environmental factors does not alone explain the causality  of any individual event, most scientists agree that smoking causes  cancer.  You just can't pin it down to the individual cigarette.   Similarly, this blog's on-going attempt to disprove linkages between GHG  accumulation in the atmosphere and weather events misses the forest for  the trees.  The industries that require free dumping grounds in the  earth's atmosphere for their profit margins must be grateful for Dr.  Pielke's support, much as the tobacco companies tobacco companies loved  their captured academic champions in the 1980's.Nowadays, climate is not as much a scientific or policy issue, as it is a  cultural phenomenon (read your Mike Hulme). For years I have advised my students that there is  little point in doing a policy analysis of the abortion issue, as the  topic was entirely political.  Perhaps one day I'll be saying the same about  climate.




Posted by
Roger Pielke, Jr.


at
8/31/2011 06:45:00 AM



31
comments


Links to this post























30 August 2011





Not Anti-Science, Just Utterly Uninformed



Yesterday, Governor Pete Shumlin of Vermont made these remarks:
I find it extraordinary that so many political leaders won’t actually  talk about the relationship between climate change, fossil fuels, our  continuing irrational exuberance about burning fossil fuels, in light of  these storm patterns that we’ve been experiencing. Listen, since I’ve  been sworn in as governor just seven months ago, I have dealt with—this  is the second major disaster as a result of storms. We had storms this  spring that flooded our downtowns and put us through many of the same  exercises that we’re going through right now. We didn’t used to get  weather patterns like this in Vermont. We didn’t get tropical storms. We  didn’t get flash flooding. It wasn’t—you know, our storm patterns  weren’t like Costa Rica; they were like Vermont.A quick look at  the following paper from 2002 -- "Climate Variability and Socioeconomic Consequences of Vermont's Natural Hazards: A Historical Perspective" (here in PDF) by Lesley-Ann Dupigny-Giroux (Vermont's state climatologist), reveals this information:
One of the most pervasive hazards that impinges upon and marks the Vermont landscape is flooding. Flooding can be categorized as one of two types: flash flooding, which has a rapid onset of six hours or less from the time of the initiating event; and flooding that has a more gradual onset. Rarely does a year elapse without a flooding event of a significant magnitude being reported in at least one of Vermont’s fourteen counties or perhaps statewide, making this the number-one hazard across the state. Between 1955 and 1999, floods accounted for $16.97 million in damage annually.And also:
[T]ropical remnants have produced widespread, and at times, catastrophic flooding. For example, the Great Flood of 1927 resulted from record rainfall totals produced by tropical storm remnants on November 3, following October precipitation totals that were already 50 percent above normal. As this decaying storm tracked directly along the spine of the Green Mountains, streams rose so rapidly that there was little time for warning. The Winooski River rose 40–45 feet above its normal level, causing land and settlement along the river to bear the brunt of the estimated $30 million in economic losses. The 1927 flood was greater than the 100-year flood on many rivers and remains today as the flood of record at many gauging stations. Eighty-four of the eighty-five fatalities during this New England-wide flood occurred in Vermont. In addition, thousands of dairy cows and other farm animals drowned. Rich topsoil on farmland either washed away or got buried under infertile silt, such that no crops could be produced for many years. Montpelier remained isolated for days and Waterbury for weeks. The flood disrupted communications across the state and with the outside world, producing a “black triangle.” And here is Table 1 from that paper:
Table 1:  Tropical Remnants that Made Landfall In/Proximate to Vermont

Name Year Month, Day
[unnamed] 1927 November 3 
Great New England 1938 September 21
#2 1949 August 29–30 
Hurricane Baker 1952 September 1–2
Hurricane Carol 1954 August 31
Tropical Storm Brenda 1960 July 30
Hurricane Donna 1960 September 12
Tropical Storm Doria 1971 August 28
Hurricane Belle 1976 August 9–10
Hurricane David 1979 September 6–7
Hurricane Frederic 1979 September 14
Hurricane Gloria 1985 September 27
Tropical Storm Chris 1988 August 29
Hurricane Hugo 1989 September 22–23
Hurricane Bob 1991 August 19
Hurricane Opal 1995 October 5–6
Hurricane Bertha 1996 July 13
Hurricane Fran 1996 September 8–9Is Governor Shumlin "anti-science" (whatever that might mean)?  No, just poorly informed.

[Thanks AS]




Posted by
Roger Pielke, Jr.


at
8/30/2011 02:46:00 PM



9
comments


Links to this post

























Certain Ignorance versus Uncertain Uncertainty



Writing in the quarterly newsletter of Risk Frontiers at Macquarie University in Sydney, Rob van den Honert has an excellent discussion (here in PDF) of the interim report of the Queensland Flood Inquiry. Some background on the topic can be found in this post from last January.

In his summary van den Honert writes of the decision of the dam operators to ignore weather forecasts of pending rainfall:
[P]redicted reservoir levels depend on expected water inflows into the dam, and that expectation would be based almost entirely upon the rainfall forecast for the catchment area. The Bureau of Meteorology supplies regular 24-hour forecasts of rainfall, and the operators also had access to the Bureau’s weather radar, even though the Bureau cautions that in some circumstances the radar can produce poor estimates, either over- or underestimating actual rainfall. Furthermore, there are far fewer rain gauges in the catchment immediately above the Wivenhoe Dam than in other areas, which means that rainfall in that area was not well recorded.

Thus [the dam operator] Seqwater claim that there were gaps in the information available on which operational decisions had to be made. This is despite Seqwater having the best rain/runoff gauge of all - the dam itself!

A 2001 Seqwater report (Feasibility of Making Pre-releases from SEQWC Reservoirs) concluded that the precipitation forecasts were not sufficiently reliable to form the basis of operational decision making for the dam. Thus this less than perfect available information was given zero weight, and not used at all to help predict reservoir levels. Effectively a “forecast” of zero rainfall was used to inform decisions about water release strategies. In other words, under the circumstances, it seems that the operators chose a scenario guaranteed to be wrong over a forecast that was likely to be uncertain.The flood disaster arguably was exacerbated by poor decision making under flawed decision processes -- decision makers chose the certainty of ignorance over the uncertain nature of uncertainty judgments.  Indeed, as van den Honert describes the rainfall forecasts were inaccurate, but this did not mean that they would have been without value.

Ultimately, the only way that Queensland gets out of this situation will be to build sufficient water retention capacity to simultaneously meet the conflicting objectives of flood mitigation and water storage as a drought buffer. In other words, there is a technological fix here that can dramatically reduce uncertainties -- but such a strategy will cost money. 




Posted by
Roger Pielke, Jr.


at
8/30/2011 06:55:00 AM



2
comments


Links to this post























29 August 2011





A Nice Analysis of Print Media Coverage of Hurricane Irene



At the NYT FiveThirtyEight blog Nate Silver uses our normalized loss database (above) and historical loss of life data to assess the relative intensity of (mostly) print media coverage of Hurricane Irene. He finds that the coverage was in line with that of other storms since 1980. I would love to see a similar analysis exclusively focused on television news coverage -- I'd hypothesize different results.




Posted by
Roger Pielke, Jr.


at
8/29/2011 04:38:00 PM



2
comments


Links to this post

























The Folly of Emissions Trading: New Zealand and Europe




Coming Clean - New Zealand's Emissions Trading Scheme Explained from Lindsay Horner on Vimeo.

The video above was brought to my attention by a student in my graduate seminar this term.  It was done by one of his classmates in grad school in New Zealand (Thanks Adam!).  The video is exceedingly well done.  If you have 15 minutes and are interested in the debacle that is New Zealand's carbon policy, have a look.

News from Europe is similarly discouraging about the prospects for emissions trading, EurActiv reports:
          	European chemical manufacturers are covertly venting huge quantities of  the powerful 'super greenhouse gas' HFC-23, according to a study by the  Swiss Federal Laboratories for Materials Science and Technology (EMPA).

The report,  published in the journal Geophysical Research Letters, says that  Western Europe's emissions of HFC-23s – an 'F' or fluorinated gas mainly  used as a refrigerant – are between 60-140% higher than officially  reported.

Italy alone was found to be emitting 10-20 times more HFC-23s than it officially reports. The greenhouse gas has a global warming potential which is 14,800 times higher than CO2.
The UK and the Netherlands also emitted around twice as much as they  claimed, although the figures for France and Germany were "within the  reported values".

"We think it is scandalous," Clare Perry, a campaigner for the  Environmental Investigations Agency, told EurActiv. "These gases have a  very high global warming potential over a short timeline."EMPA, the Swiss agency that conducted the research, explains the significance:
International agreements such as the Kyoto Protocol to reduce greenhouse  gases (GHG) basically have one snag: it is almost impossible to  independently verify whether participating countries abide by the  agreement. Thus the evaluation of whether or not the countries have  achieved their reduction targets is based on the official reports by the  countries that are signatories to the UNFCCC (‘United Nations Framework  Convention on Climate Change’). If they report reduced emissions  they're sitting pretty; if not, they are pilloried.Some might say that the response should be more regulation, more reporting, more rules -- all negotiated through a comprehensive global framework. Of course, that approach hasn't gotten very far to date.




Posted by
Roger Pielke, Jr.


at
8/29/2011 02:53:00 PM



9
comments


Links to this post

























Guest Post: Kevin Vranes on the Virginia Earthquake



NOTE: This is a guest post by Kevin Vranes. 

The  overwrought reaction to the M5.8 Virgina earthquake on Tuesday had a  lot of native Californians snickering (ok, me included, I grew up just  south of San Francisco), but I had to concede that a M5.8 in the east is  not the same thing in the well-prepared west.  The fact is, the eastern  seaboard has plenty of shaking in its geologic history, but little in  its human history.  The frequency of very large quakes on the eastern  seaboard is much longer than 1-2 generations, a period which in  California seems to keep the risk fresh in the mind of locals and in the  policy considerations of local governments.

Building  codes in the U.S. have traditionally been highly localized, and only  recently are beginning to reflect the realization that almost every  state in the U.S. has some seismic risk and therefore codes should  incorporate seismic design principles. Combine slow code change with old  building stock (apparently the building stock is older in D.C. than in  any of the 50 states - link), and you have an area at much higher relative risk to moderate shaking than California.  

The question we should be asking is, what is the true risk?  Since this is an intraplate region  with lots of old, hidden faults that do not move often enough to reveal  shaking risk, this is a difficult question to answer (perhaps nearing  impossible in the foreseeable future).  But what about from an economic  damages perspective?  In the absence of seismic data, can some measure  of risk be calculated?

In 2009 Roger and I published a paper in Natural Hazards Review  to examine this question. The analysis was an attempt to put historical  quakes into current-day context by asking essentially this question:  “If the 1906 San Francisco happened again today, with today’s  population, increase in wealth and increase in damage mitigation, what  would we figure the economic losses would be?”  We did this calculation  for every earthquake in the U.S. since 1900 for which we could find a  credible estimate of economic losses -- 80 in all.  How does this apply  to east coast earthquakes, and therefore how does it reflect on  Tuesday’s quake?  By giving us a measure of the frequency of quakes that  cause economic damages in a certain region.

So what does our analysis tell us about Tuesday’s Virginia earthquake?  Unfortunately, the answer is: just about nothing.  Since 1900 only two quakes have occurred in the east that were given  damage estimates: a 1944 quake in Massena, NY (on the Canadian border,  as far from NYC as you can get in New York state) and a 1954 event in  Wilkes-Barre, Pennsylvania.  The Massena quake was given a $1.5M - $2M  price tag, and the Wilkes-Barre event was given a $1M estimate.   Although damaging events have occurred in the mid-Atlantic and  southeast in human history, none have occurred since 1900, the period  for which we have good economic comparison data.

And  this is the problem.  We know the major quakes can occur in the  intraplate east, but they happen so infrequently and the last big ones  happened so long ago, they tell us very little about what would occur  today with the same shaking conditions.  The two major historic quakes  in the east occurred in 1811 (New Madrid, Missouri) and 1886  (Charleston, SC).  Damages from the Charleston event was given a price  tag of about $5 million in 1886 dollars.  By comparison, the 1906 San  Francisco earthquake was estimated at over $500 million in 1906 dollars.

Were these quakes to occur again today damage would undoubtedly be extreme, but how extreme?  What’s left is to model with HAZUS,  which can give a peek into what kind of damages you might expect from  certain shaking types, and hope that your estimate for shaking risk in  certain intraplate regions is fairly accurate.  Whether it is?  We’ll  find out when the next big eastern seaboard quake happens near a major  city. 




Posted by
Roger Pielke, Jr.


at
8/29/2011 11:01:00 AM



2
comments


Links to this post























28 August 2011





How Intellectually Interesting is the "Debate" over Global Warming and Hurricanes?








Posted by
Roger Pielke, Jr.


at
8/28/2011 10:31:00 AM



4
comments


Links to this post























26 August 2011





Hurricane Irene Damage Analogues?



[UPDATE August 27: This AP news story calls the ICAT Damage Estimator a "model" that "predicts" $4.7 billion in damage. Wrong (The $4.7B is the average of the  27 analogues as you can see in the image above).  The ICAT site is simply a tool to look at historical analogues and offers no predictions of the future.  The WSJ does a much better job discussing the issue.]

I've had a bunch of calls today, presumably following up from Nate Silver's post at the NYT, on potential damage from Irene.

I have used the ICAT Damage Estimator to look at all storms that fall within the spread of the various model projections (displayed above, as of 9AM MT) and here are the top  6 storms that come up.

STORM NAME LANDFALL DATE DAMAGE
RANK CURRENT DAMAGE 
($ 2011) BASE DAMAGE 
($) LANDFALL 
STATE CATEGORY WINDS
(MPH) 
 
  New England Sep 21,1938  8  46,160,000,000  306,000,000  NY  2  100  
  Carol Aug 31,1954  16  19,240,000,000  460,000,000  NY  2  100  
  Agnes Jun 22,1972  18  18,880,000,000  2,000,000,000  NY  TS  65  
  Storm 7 in 1944 Sep 14,1944  31  10,670,000,000  90,000,000  NY  1  85  
  Storm 7 in 1944 Sep 14,1944  36  8,320,000,000  10,000,000  NC  2  105  
  Storm 8 in 1933 Aug 23,1933  52  4,880,000,000  27,000,000  NC  1  80 

None of the storms is really a good analogue.  We should expect to see damage along the entire eastern seaboard, as well as a considerable amount of damage from inland flooding (not included in these numbers).

It wouldn't be anything more than a guess to speculate at this point on Irene's total impact, but it does seem safe to say that it's effects will be widespread and the damage total considerable.




Posted by
Roger Pielke, Jr.


at
8/26/2011 09:10:00 AM



2
comments


Links to this post


























Older Posts

Home




Subscribe to:
Posts (Atom)






Like what you read here?





Please Consider a Donation











Subscribe Now!

 Click here 











Search This Blog

 











About Me





Roger Pielke, Jr.


I am a professor of environmental studies at the Center for Science and Technology Policy Research at the University of Colorado at Boulder. I also have an appointments as a Visiting Senior Fellow, Mackinder Programme, London School of Economics and Senior Visiting Fellow at the Consortium for Science, Policy and Outcomes at Arizona State University. I am also a Senior Fellow of The Breakthrough Institute, a progressive think tank.

View my complete profile











Some Links

My CU homepageOAQ About Roger Pielke, Jr.Q&A on Climate Policy 6/2009My sports blogMy publicationsThe Climate FixThe Honest Broker at AmazonMy archived posts at PrometheusRejected commentsContact me: rpielkejr(at)gmail.com
















The Climate Fix: What Scientists and Politicians Won't Tell You About Global Warming (Basic Books)
















Presidential Science Advisors: Perspectives and Reflections on Science, Policy and Politics (Springer, 2010)
















The Honest Broker: Making Sense of Science in Policy and Politics (Cambridge, 2007)











Recent Comments













Blog Archive






▼ 

2011
(272)



▼ 

September
(3)

Faith-Based Education and a Return to Shop Class
Energy Efficiency and Carbon Emissions: Class Assi...
Retraction, Remote Sensing and Due Process








          ► 
        


August
(33)

Oil Shocks and Good Times for the Global Economy
Comment of the Day: The Wrong Side of History, Sci...
Not Anti-Science, Just Utterly Uninformed
Certain Ignorance versus Uncertain Uncertainty
A Nice Analysis of Print Media Coverage of Hurrica...
The Folly of Emissions Trading: New Zealand and Eu...
Guest Post: Kevin Vranes on the Virginia Earthquak...
How Intellectually Interesting is the "Debate" ove...
Hurricane Irene Damage Analogues?
Globalization Schmobalization
A Democracy Working
Wednesday Climate Linkage
Hurricane Irene and the ICAT Damage Estimator
College Tuition Evolves in California
Ink Blots, Ambiguity and Outcomes in the Real Worl...
More Fun With Uncertainty Guidance
Fun With Epistemic and Aleatory Uncertainties
Friday Funny - Deniers Risk Alien Attack
CPR Colorado Matters Interview on In-State Tuition...
Obituary: John Marburger
Academic Exercises and Real World Commitments
In-State Tuition Reform Continued
Who Says Universities Aren't Conservative Places?
Friday Funny
How Many Findings of the IPCC AR4 WG I are Incorre...
Surging Retractions in Scientific Publishing
Does Blogging Lead to More Readers of Academic Pap...
Beyond Assessment at the Science-Policy Interface
Update on a Polar Mystery
At The Least Thing: EPL and Bundesliga Competition...
Wanted: Less Spin, More Informed Debate
A Democracy Paradox in Studies of Science and Tech...
John H. Marburger: 1941-2011








          ► 
        


July
(21)

Reader Mail on In-State Tuition Reform
Scientists: You Are No Longer Politically Useful
The Simple Math and Logic Underpinning Climate Pra...
Commentary in the Chronicle on In-State Tuition Re...
Climate Pragmatism
Bayh-Dole Meets Pay-for-Play
The Policy Advisor's Dilemma
When Politicians Put Experts Between a Rock and a ...
High Praise for The Climate Fix
Sarewitz on NSF Broader Impacts
The 2011 Tornado Losses in Context: A Preliminary ...
American Politics in a Single Graph
Making Stuff Up at Real Climate
A Bad Analogy in Australia's  New Climate Policy P...








          ► 
        


June
(17)







          ► 
        


May
(40)







          ► 
        


April
(40)







          ► 
        


March
(37)







          ► 
        


February
(40)







          ► 
        


January
(41)









          ► 
        


2010
(592)





          ► 
        


December
(18)







          ► 
        


November
(54)







          ► 
        


October
(70)







          ► 
        


September
(59)







          ► 
        


August
(57)







          ► 
        


July
(45)







          ► 
        


June
(65)







          ► 
        


May
(48)







          ► 
        


April
(46)







          ► 
        


March
(43)







          ► 
        


February
(41)







          ► 
        


January
(46)









          ► 
        


2009
(391)





          ► 
        


December
(59)







          ► 
        


November
(58)







          ► 
        


October
(80)







          ► 
        


September
(58)







          ► 
        


August
(60)







          ► 
        


July
(48)







          ► 
        


June
(28)


















  












  













 









